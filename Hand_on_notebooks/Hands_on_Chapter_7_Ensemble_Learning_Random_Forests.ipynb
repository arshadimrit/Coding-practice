{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as graph\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "\n",
    "- Hard voting: Predict class which gets most votes, majority-vote\n",
    "- Soft voting: Predict class with highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], \n",
    "    voting = 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     cr...\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                                  probability=False, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     crit...\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=42, verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                                  probability=True, random_state=42,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", probability=True, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging: Same classifier on different subsets of data, with replacement ------> Bootstrapping\n",
    "- Pasting: Same classifier on different subsets of data, without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of Bag evaluation \n",
    "Use the part of training set not used during bagging to perform validation, so cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9253333333333333\n",
      "[[0.30310881 0.69689119]\n",
      " [0.37531486 0.62468514]\n",
      " [0.99742268 0.00257732]\n",
      " [0.01554404 0.98445596]\n",
      " [0.02604167 0.97395833]\n",
      " [0.09259259 0.90740741]\n",
      " [0.43854749 0.56145251]\n",
      " [0.05167959 0.94832041]\n",
      " [0.95538058 0.04461942]\n",
      " [0.82945736 0.17054264]\n",
      " [0.59487179 0.40512821]\n",
      " [0.04712042 0.95287958]\n",
      " [0.71761658 0.28238342]\n",
      " [0.86170213 0.13829787]\n",
      " [0.91755319 0.08244681]\n",
      " [0.08673469 0.91326531]\n",
      " [0.02645503 0.97354497]\n",
      " [0.90488432 0.09511568]\n",
      " [0.71128609 0.28871391]\n",
      " [0.93979058 0.06020942]\n",
      " [0.05093834 0.94906166]\n",
      " [0.26530612 0.73469388]\n",
      " [0.90159574 0.09840426]\n",
      " [0.97831978 0.02168022]\n",
      " [0.94240838 0.05759162]\n",
      " [0.00261097 0.99738903]\n",
      " [0.94429708 0.05570292]\n",
      " [1.         0.        ]\n",
      " [0.02295918 0.97704082]\n",
      " [0.73506494 0.26493506]\n",
      " [0.         1.        ]\n",
      " [0.99742268 0.00257732]\n",
      " [0.00555556 0.99444444]\n",
      " [0.09066667 0.90933333]\n",
      " [0.10126582 0.89873418]\n",
      " [0.97643979 0.02356021]\n",
      " [0.01634877 0.98365123]\n",
      " [0.52066116 0.47933884]\n",
      " [0.01822917 0.98177083]\n",
      " [0.9974026  0.0025974 ]\n",
      " [0.08       0.92      ]\n",
      " [0.35309278 0.64690722]\n",
      " [0.99507389 0.00492611]\n",
      " [0.97680412 0.02319588]\n",
      " [0.01861702 0.98138298]\n",
      " [1.         0.        ]\n",
      " [0.99739583 0.00260417]\n",
      " [0.04787234 0.95212766]\n",
      " [0.97964377 0.02035623]\n",
      " [0.03743316 0.96256684]\n",
      " [0.97282609 0.02717391]\n",
      " [0.86458333 0.13541667]\n",
      " [0.93702771 0.06297229]\n",
      " [0.81052632 0.18947368]\n",
      " [0.01861702 0.98138298]\n",
      " [0.06493506 0.93506494]\n",
      " [0.84068627 0.15931373]\n",
      " [0.01069519 0.98930481]\n",
      " [0.01041667 0.98958333]\n",
      " [0.04020101 0.95979899]\n",
      " [0.85082873 0.14917127]\n",
      " [0.65206186 0.34793814]\n",
      " [0.71072319 0.28927681]\n",
      " [0.98655914 0.01344086]\n",
      " [0.01038961 0.98961039]\n",
      " [0.7989418  0.2010582 ]\n",
      " [0.97889182 0.02110818]\n",
      " [0.99204244 0.00795756]\n",
      " [0.62698413 0.37301587]\n",
      " [0.98477157 0.01522843]\n",
      " [0.3443038  0.6556962 ]\n",
      " [0.29545455 0.70454545]\n",
      " [0.4507772  0.5492228 ]\n",
      " [0.71087533 0.28912467]\n",
      " [0.01546392 0.98453608]\n",
      " [0.30104712 0.69895288]\n",
      " [0.88772846 0.11227154]\n",
      " [1.         0.        ]\n",
      " [0.02368421 0.97631579]\n",
      " [0.95687332 0.04312668]\n",
      " [0.00253165 0.99746835]\n",
      " [0.21842105 0.78157895]\n",
      " [0.15789474 0.84210526]\n",
      " [0.43782383 0.56217617]\n",
      " [0.99488491 0.00511509]\n",
      " [0.03655352 0.96344648]\n",
      " [0.67385445 0.32614555]\n",
      " [0.05194805 0.94805195]\n",
      " [0.02849741 0.97150259]\n",
      " [0.         1.        ]\n",
      " [0.37566138 0.62433862]\n",
      " [0.9973822  0.0026178 ]\n",
      " [0.0025641  0.9974359 ]\n",
      " [0.0265252  0.9734748 ]\n",
      " [0.01312336 0.98687664]\n",
      " [0.81182796 0.18817204]\n",
      " [0.62597403 0.37402597]\n",
      " [0.04699739 0.95300261]\n",
      " [0.99477807 0.00522193]\n",
      " [0.27027027 0.72972973]\n",
      " [0.69863014 0.30136986]\n",
      " [0.00526316 0.99473684]\n",
      " [0.109375   0.890625  ]\n",
      " [0.43896104 0.56103896]\n",
      " [0.98205128 0.01794872]\n",
      " [0.04603581 0.95396419]\n",
      " [0.96858639 0.03141361]\n",
      " [0.39841689 0.60158311]\n",
      " [0.30213904 0.69786096]\n",
      " [0.98704663 0.01295337]\n",
      " [0.23333333 0.76666667]\n",
      " [0.85526316 0.14473684]\n",
      " [0.27363184 0.72636816]\n",
      " [0.75062344 0.24937656]\n",
      " [0.99212598 0.00787402]\n",
      " [0.99475066 0.00524934]\n",
      " [0.         1.        ]\n",
      " [0.00283286 0.99716714]\n",
      " [0.49322493 0.50677507]\n",
      " [0.99212598 0.00787402]\n",
      " [0.04935065 0.95064935]\n",
      " [0.99255583 0.00744417]\n",
      " [0.97382199 0.02617801]\n",
      " [0.99742931 0.00257069]\n",
      " [0.93963255 0.06036745]\n",
      " [0.98408488 0.01591512]\n",
      " [0.02610966 0.97389034]\n",
      " [0.92741935 0.07258065]\n",
      " [0.9602122  0.0397878 ]\n",
      " [0.01634877 0.98365123]\n",
      " [0.24871795 0.75128205]\n",
      " [0.8556962  0.1443038 ]\n",
      " [0.34042553 0.65957447]\n",
      " [0.90789474 0.09210526]\n",
      " [0.00508906 0.99491094]\n",
      " [0.02972973 0.97027027]\n",
      " [0.78891821 0.21108179]\n",
      " [0.74611399 0.25388601]\n",
      " [0.539801   0.460199  ]\n",
      " [0.85233161 0.14766839]\n",
      " [0.91542289 0.08457711]\n",
      " [0.09560724 0.90439276]\n",
      " [0.80203046 0.19796954]\n",
      " [0.04761905 0.95238095]\n",
      " [0.         1.        ]\n",
      " [0.10904255 0.89095745]\n",
      " [0.77142857 0.22857143]\n",
      " [0.97938144 0.02061856]\n",
      " [0.99748111 0.00251889]\n",
      " [0.04461942 0.95538058]\n",
      " [0.00531915 0.99468085]\n",
      " [0.05835544 0.94164456]\n",
      " [0.03191489 0.96808511]\n",
      " [0.98421053 0.01578947]\n",
      " [0.97650131 0.02349869]\n",
      " [0.86933333 0.13066667]\n",
      " [0.99730458 0.00269542]\n",
      " [1.         0.        ]\n",
      " [0.88802083 0.11197917]\n",
      " [0.01373626 0.98626374]\n",
      " [0.68219178 0.31780822]\n",
      " [0.28571429 0.71428571]\n",
      " [0.05263158 0.94736842]\n",
      " [0.01298701 0.98701299]\n",
      " [0.35309278 0.64690722]\n",
      " [0.99494949 0.00505051]\n",
      " [0.96632124 0.03367876]\n",
      " [0.         1.        ]\n",
      " [0.99204244 0.00795756]\n",
      " [0.04603581 0.95396419]\n",
      " [0.00522193 0.99477807]\n",
      " [0.95263158 0.04736842]\n",
      " [0.00539084 0.99460916]\n",
      " [0.01081081 0.98918919]\n",
      " [0.99746835 0.00253165]\n",
      " [0.03485255 0.96514745]\n",
      " [0.85900783 0.14099217]\n",
      " [0.94293478 0.05706522]\n",
      " [0.04404145 0.95595855]\n",
      " [0.93877551 0.06122449]\n",
      " [0.90673575 0.09326425]\n",
      " [0.97435897 0.02564103]\n",
      " [0.01639344 0.98360656]\n",
      " [0.00519481 0.99480519]\n",
      " [0.99740933 0.00259067]\n",
      " [0.22020725 0.77979275]\n",
      " [0.98737374 0.01262626]\n",
      " [0.09669211 0.90330789]\n",
      " [0.03448276 0.96551724]\n",
      " [0.97911227 0.02088773]\n",
      " [0.         1.        ]\n",
      " [0.15143603 0.84856397]\n",
      " [0.89147287 0.10852713]\n",
      " [0.90339426 0.09660574]\n",
      " [0.66047745 0.33952255]\n",
      " [0.70277778 0.29722222]\n",
      " [0.02688172 0.97311828]\n",
      " [0.26525199 0.73474801]\n",
      " [0.98128342 0.01871658]\n",
      " [0.91948052 0.08051948]\n",
      " [0.92167102 0.07832898]\n",
      " [0.98477157 0.01522843]\n",
      " [0.032      0.968     ]\n",
      " [0.01358696 0.98641304]\n",
      " [0.08695652 0.91304348]\n",
      " [0.52631579 0.47368421]\n",
      " [0.         1.        ]\n",
      " [0.03100775 0.96899225]\n",
      " [0.97461929 0.02538071]\n",
      " [0.09414758 0.90585242]\n",
      " [0.13043478 0.86956522]\n",
      " [0.8968254  0.1031746 ]\n",
      " [0.05729167 0.94270833]\n",
      " [0.32608696 0.67391304]\n",
      " [0.         1.        ]\n",
      " [0.99750623 0.00249377]\n",
      " [0.02307692 0.97692308]\n",
      " [0.01856764 0.98143236]\n",
      " [0.91906005 0.08093995]\n",
      " [0.87700535 0.12299465]\n",
      " [0.95967742 0.04032258]\n",
      " [0.02088773 0.97911227]\n",
      " [0.06806283 0.93193717]\n",
      " [0.95465995 0.04534005]\n",
      " [0.12564103 0.87435897]\n",
      " [0.01010101 0.98989899]\n",
      " [0.28157895 0.71842105]\n",
      " [0.97340426 0.02659574]\n",
      " [0.83076923 0.16923077]\n",
      " [0.12244898 0.87755102]\n",
      " [0.74489796 0.25510204]\n",
      " [0.95336788 0.04663212]\n",
      " [0.14133333 0.85866667]\n",
      " [0.11917098 0.88082902]\n",
      " [0.99238579 0.00761421]\n",
      " [0.         1.        ]\n",
      " [0.02051282 0.97948718]\n",
      " [0.01322751 0.98677249]\n",
      " [0.32275132 0.67724868]\n",
      " [0.84126984 0.15873016]\n",
      " [0.06632653 0.93367347]\n",
      " [0.99481865 0.00518135]\n",
      " [0.86       0.14      ]\n",
      " [0.00260417 0.99739583]\n",
      " [0.73969072 0.26030928]\n",
      " [0.99456522 0.00543478]\n",
      " [0.00507614 0.99492386]\n",
      " [0.99230769 0.00769231]\n",
      " [0.03037975 0.96962025]\n",
      " [0.01842105 0.98157895]\n",
      " [0.1055409  0.8944591 ]\n",
      " [0.26370757 0.73629243]\n",
      " [0.81558442 0.18441558]\n",
      " [0.05585106 0.94414894]\n",
      " [0.98961039 0.01038961]\n",
      " [0.66666667 0.33333333]\n",
      " [0.05759162 0.94240838]\n",
      " [0.64720812 0.35279188]\n",
      " [0.83157895 0.16842105]\n",
      " [0.00275482 0.99724518]\n",
      " [0.98895028 0.01104972]\n",
      " [0.01061008 0.98938992]\n",
      " [0.         1.        ]\n",
      " [0.75265957 0.24734043]\n",
      " [0.         1.        ]\n",
      " [0.99483204 0.00516796]\n",
      " [0.0880829  0.9119171 ]\n",
      " [0.78648649 0.21351351]\n",
      " [0.14325069 0.85674931]\n",
      " [0.98691099 0.01308901]\n",
      " [0.87696335 0.12303665]\n",
      " [0.         1.        ]\n",
      " [0.04134367 0.95865633]\n",
      " [0.18701299 0.81298701]\n",
      " [0.0880829  0.9119171 ]\n",
      " [0.         1.        ]\n",
      " [0.96675192 0.03324808]\n",
      " [0.83585859 0.16414141]\n",
      " [0.17819149 0.82180851]\n",
      " [0.89276139 0.10723861]\n",
      " [0.03645833 0.96354167]\n",
      " [0.59547739 0.40452261]\n",
      " [0.10362694 0.89637306]\n",
      " [0.9453125  0.0546875 ]\n",
      " [0.85347044 0.14652956]\n",
      " [0.008      0.992     ]\n",
      " [0.94986807 0.05013193]\n",
      " [0.91421569 0.08578431]\n",
      " [0.01049869 0.98950131]\n",
      " [0.0546875  0.9453125 ]\n",
      " [0.99494949 0.00505051]\n",
      " [0.02465753 0.97534247]\n",
      " [0.98915989 0.01084011]\n",
      " [0.07808564 0.92191436]\n",
      " [0.89005236 0.10994764]\n",
      " [1.         0.        ]\n",
      " [0.01058201 0.98941799]\n",
      " [0.04761905 0.95238095]\n",
      " [0.6461126  0.3538874 ]\n",
      " [0.         1.        ]\n",
      " [0.99737533 0.00262467]\n",
      " [0.66497462 0.33502538]\n",
      " [0.82880435 0.17119565]\n",
      " [0.98445596 0.01554404]\n",
      " [0.68814433 0.31185567]\n",
      " [0.43005181 0.56994819]\n",
      " [0.02419355 0.97580645]\n",
      " [0.83561644 0.16438356]\n",
      " [0.00765306 0.99234694]\n",
      " [0.99493671 0.00506329]\n",
      " [0.77308707 0.22691293]\n",
      " [0.99485861 0.00514139]\n",
      " [0.99733333 0.00266667]\n",
      " [0.82245431 0.17754569]\n",
      " [0.22459893 0.77540107]\n",
      " [0.14986376 0.85013624]\n",
      " [0.21220159 0.78779841]\n",
      " [0.00260417 0.99739583]\n",
      " [0.78756477 0.21243523]\n",
      " [0.8556962  0.1443038 ]\n",
      " [0.0620155  0.9379845 ]\n",
      " [0.99737533 0.00262467]\n",
      " [0.96833773 0.03166227]\n",
      " [0.98992443 0.01007557]\n",
      " [0.01319261 0.98680739]\n",
      " [0.07692308 0.92307692]\n",
      " [0.94722955 0.05277045]\n",
      " [0.91836735 0.08163265]\n",
      " [0.99459459 0.00540541]\n",
      " [0.23544974 0.76455026]\n",
      " [0.99220779 0.00779221]\n",
      " [0.1314433  0.8685567 ]\n",
      " [0.94933333 0.05066667]\n",
      " [0.0388601  0.9611399 ]\n",
      " [0.9947644  0.0052356 ]\n",
      " [0.9843342  0.0156658 ]\n",
      " [0.99208443 0.00791557]\n",
      " [0.         1.        ]\n",
      " [0.95490716 0.04509284]\n",
      " [0.02025316 0.97974684]\n",
      " [0.05483029 0.94516971]\n",
      " [0.06005222 0.93994778]\n",
      " [0.         1.        ]\n",
      " [0.99734043 0.00265957]\n",
      " [0.97943445 0.02056555]\n",
      " [0.         1.        ]\n",
      " [0.95502646 0.04497354]\n",
      " [0.07945205 0.92054795]\n",
      " [0.99238579 0.00761421]\n",
      " [0.23218997 0.76781003]\n",
      " [0.00520833 0.99479167]\n",
      " [0.05343511 0.94656489]\n",
      " [0.00520833 0.99479167]\n",
      " [0.79947917 0.20052083]\n",
      " [0.08947368 0.91052632]\n",
      " [0.11898734 0.88101266]\n",
      " [1.         0.        ]\n",
      " [0.94666667 0.05333333]\n",
      " [0.24031008 0.75968992]\n",
      " [0.95039164 0.04960836]\n",
      " [0.05527638 0.94472362]\n",
      " [0.1300813  0.8699187 ]\n",
      " [0.99463807 0.00536193]\n",
      " [0.91729323 0.08270677]\n",
      " [0.54005168 0.45994832]\n",
      " [0.88624339 0.11375661]\n",
      " [0.99736842 0.00263158]\n",
      " [0.03655352 0.96344648]\n",
      " [0.94444444 0.05555556]\n",
      " [0.02393617 0.97606383]\n",
      " [0.16304348 0.83695652]\n",
      " [0.93029491 0.06970509]\n",
      " [0.99741602 0.00258398]\n",
      " [0.06994819 0.93005181]\n",
      " [0.65945946 0.34054054]]\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, \n",
    "                            oob_score=True)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print(bag_clf.oob_score_)\n",
    "print(bag_clf.oob_decision_function_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Patches and Random subspaces\n",
    "\n",
    "Can sample features, using the hyperparameters \"max_features\" and \"boostrap_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of random forests, done by bagging classifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16), \n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra-trees\n",
    "Extremely randomized trees: done by using random threshold for each features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "With random forests, easy to measure relative importance of each feature ------------> Use weighted average of tree node and how they reduce impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.1033218990773931\n",
      "sepal width (cm) 0.023390098125678115\n",
      "petal length (cm) 0.45148112901130927\n",
      "petal width (cm) 0.42180687378561943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs = -1)\n",
    "rnd_clf.fit(iris['data'], iris['target'])\n",
    "\n",
    "for name, score in zip(iris['feature_names'], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.hot,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c0df8f6d0d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrnd_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Not Important'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Very Important'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-91b7007f07b1>\u001b[0m in \u001b[0;36mplot_digit\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     plt.imshow(image, cmap = mpl.cm.hot,\n\u001b[1;32m      4\u001b[0m                interpolation=\"nearest\")\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4 into shape (28,28)"
     ]
    }
   ],
   "source": [
    "plot_digit(rnd_clf.feature_importances_)\n",
    "\n",
    "cbar = graph.colorbar(ticks = [rnd_clf.feature_importances_.min(), rnd_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels(['Not Important', 'Very Important'])\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "Ensemble methods that combine several weak learners into a strong learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "- Adaptive Boosting\n",
    "- Focus on instances that previous predictor underfitted\n",
    "    - New predictors focusing more on hard cases ----> Obtained by increasing relative weight of misclassified training instances\n",
    "- Like baggig and pasting. BUT PREDICTORS HAVE DIFFERENT WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                         class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=1,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort='deprecated',\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.5, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth = 1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "- Sequentially add predictors to ensemble, each one correcting predecessor\n",
    "- Does not tweak instance weights, BUT FIT NEW PREDICTOR TO RESIDUAL ERRORS MADE BY PREVIOUS PREDICTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75026781]\n"
     ]
    }
   ],
   "source": [
    "X_new = np.array([[0.8]])\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=1.0, loss='ls', max_depth=2,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=3,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=2,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=48,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators=120)\n",
    "gbrt.fit(x_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(x_val)]\n",
    "best_n_estimators = np.argmin(errors)\n",
    "\n",
    "print(best_n_estimators)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth = 2, n_estimators=best_n_estimators)\n",
    "gbrt_best.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAcoUlEQVR4nO3de5RUZ5nv8e9TVV1V9BVomm5o7jQJArkOucdrZjzESxgnURM9yzgnXkaTNTqemWM8nnFmPHPOMs5MMqMTb8uo0dEEJ0ZlFCfjGDXHBAlgYggBTEMIl0BoLgG6oS9V9Zw/aldTaZpQDQ27a+/fZ61eVO29q+p52V2/evvd795l7o6IiERXIuwCRETkzFLQi4hEnIJeRCTiFPQiIhGnoBcRibhU2AUMNWnSJJ81a1bYZcgYtqWrB4A5LXUhVyIydqxdu3avu7cMt27MBf2sWbNYs2ZN2GXIGPbOL68EYNkHrwi5EpGxw8yeP9E6Dd2IiEScgl5EJOIU9CIiEaegFxGJOAW9iEjEKehFRCJOQS8iEnGRCfqdLx3lH/5jE1v39oRdiojImBKZoH/pSD+ff7iTjbsPhV2KiMiYEpmgn9yQBeDFQ30hVyIiMrZEJuib69IkE8aew71hlyIiMqZEJugTCaOlPqMevYjIEJEJeoDWxgx7DivoRUTKRSroWxqy7DmkoRsRkXKRCvrJ6tGLiBwnUkHf2pBlf08//blC2KWIiIwZkQr6yY0ZALq61asXESmJVNC3BkGvcXoRkWMiFfQ6aUpE5HjRCvrS0I1OmhIRGRSpoG+uy5AwNPNGRKRMpII+mTBaGjK8qDF6EZFBkQp6KI7Tq0cvInJMBINe17sRESkXvaBvzOpgrIhImegFfUOGvd39DOR1dqyICEQw6Fsbi3Pp9+rsWBERIIJBP7mhOJde4/QiIkWRC/pSj16XQRARKYpc0JfOjtUUSxGRosgFfXNdGjP16EVESiIX9Klkgkn1+gISEZGSyAU9lE6aUo9eRAQiGvStjVnNuhERCUQ06DV0IyJSEsmgn9yQZV9Pn86OFREhokHf1pTFHbrUqxcRiWbQl747VgdkRUQiGvTHvjtWQS8iUlHQm9kSM9tkZp1mdvsw6zNmtixYv8rMZg1ZP8PMus3sz0en7FfW1qQvCRcRKTlp0JtZErgbuBZYANxkZguGbHYLcMDdO4C7gDuGrL8T+Mnpl1uZibVpapLGbvXoRUQq6tFfCnS6+xZ37wfuB5YO2WYpcG9w+wHgGjMzADP7Q+A5YP3olHxyiYQxuSGroRsRESoL+nZge9n9HcGyYbdx9xxwEGg2s3rg48DfnH6pIzO5UWfHiojAmT8Y+9fAXe7e/UobmdkHzGyNma3p6uoalRdu09mxIiJAZUG/E5hedn9asGzYbcwsBTQB+4DLgM+a2Vbgo8D/NLPbhr6Au3/F3Re7++KWlpYRN2I4rY1ZXjyoHr2ISKqCbVYD88xsNsVAvxF415BtlgM3AyuBG4CH3d2BV5c2MLO/Brrd/Z9Hoe6Tam3McrgvR09fjrpMJc0UEYmmk/bogzH324CHgA3Ad919vZl92syuCza7h+KYfCfwMeC4KZhnm06aEhEpqqir6+4rgBVDln2q7HYv8PaTPMdfn0J9p6yt8dhc+jkt9WfzpUVExpRInhkLMLn03bGH1aMXkXiLbNCXzo7drQOyIhJzkQ36+kyKunRSUyxFJPYiG/RQ+qYp9ehFJN4U9CIiERfxoM/owmYiEnvRDvqmLHsO9VE8d0tEJJ6iHfQNWfrzBQ4cGQi7FBGR0EQ66I99AYmGb0QkviId9LoMgohI5INeJ02JiEQ66Nsas6QSxvYDR8IuRUQkNJEO+lQyQfuEcTy/T0EvIvEV6aAHmDGxlm37FfQiEl+xCHr16EUkziIf9DObazl4dICDmksvIjEV+aCfMbEOgOf394RciYhIOCIf9DObawE0fCMisRX5oJ8xsRj0OiArInEV+aCvy6SYVJ/h+X0auhGReIp80ENx+EZDNyISV/EIes2lF5EYi0XQz2iuZfehXnoH8mGXIiJy1sUi6Gc21+IOO3TNGxGJoVgE/eBceo3Ti0gMxSLoS3PpNU4vInEUi6BvrktTl06qRy8isRSLoDczpmvmjYjEVCyCHkpz6XXSlIjET4yCvo7t+4+SL3jYpYiInFUxCvpa+vMFduuLwkUkZuIT9INTLDV8IyLxEp+gL02x1MwbEYmZ2AT9lKYsqYTxvGbeiEjMxCboU8kE0ydq5o2IxE9sgh70ReEiEk8VBb2ZLTGzTWbWaWa3D7M+Y2bLgvWrzGxWsPxSM3sy+Pmtmb1tdMsfmZnNtWzbdwR3TbEUkfg4adCbWRK4G7gWWADcZGYLhmx2C3DA3TuAu4A7guVPA4vd/UJgCfBlM0uNVvEjNbO5jsN9OQ4cGQirBBGRs66SHv2lQKe7b3H3fuB+YOmQbZYC9wa3HwCuMTNz9yPunguWZ4FQu9Izg++P3apxehGJkUqCvh3YXnZ/R7Bs2G2CYD8INAOY2WVmth5YB/xJWfAPMrMPmNkaM1vT1dU18lZUSFMsRSSOzvjBWHdf5e4LgUuAT5hZdphtvuLui919cUtLyxmrZXrQo9cBWRGJk0qCficwvez+tGDZsNsEY/BNwL7yDdx9A9ANLDrVYk9XtibJlKYsz+/X0I2IxEclQb8amGdms80sDdwILB+yzXLg5uD2DcDD7u7BY1IAZjYTmA9sHZXKT9GMibUauhGRWDnpDBh3z5nZbcBDQBL4mruvN7NPA2vcfTlwD/AtM+sE9lP8MAC4GrjdzAaAAvBhd997JhpSqZnNtTy88cwdBxARGWsqmuro7iuAFUOWfarsdi/w9mEe9y3gW6dZ46ia2VzH3u4d9PTlqMuENtNTROSsidWZsaDvjxWR+Ilf0A9erlhBLyLxELugn9FcmmKpmTciEg+xC/qmcTW0NGTY9OLhsEsRETkrYhf0AIumNvL0zoNhlyEiclbEMujPa2+ic083R/qPuxqDiEjkxDLoF7U3UXDYsEvDNyISfbEM+vOmNQFo+EZEYiGWQd/WmKW5Ls06Bb2IxEAsg97MWNTepB69iMRCLIMeigdkn93TTe9APuxSRETOqNgG/aL2JvIFZ8OuQ2GXIiJyRsU26HVAVkTiIrZBP7Upy0QdkBWRGIht0JsZC6c2sm6nhm5EJNpiG/QQHJB98bAOyIpIpMU66C+ZNZFcwVm9dX/YpYiInDGxDvrL5kwknUrwy036akERia5YB31tOsVlsyfyy98p6EUkumId9ACvPaeFZ/d088JLR8MuRUTkjFDQn9MCwCPq1YtIRMU+6Dsm1zO1KavhGxGJrNgHvZnxmnNa+NWzexnIF8IuR0Rk1MU+6KE4fHO4L8eT218KuxQRkVGnoAeu7JhEMmH8YtOesEsRERl1CnqgaVwNC6c2qkcvIpGkoA/Mb2tgw67DuHvYpYiIjCoFfWB+WyP7e/rp6u4LuxQRkVGloA/Mn9IAwMZdh0OuRERkdCnoA/PbGgHYuFuXLRaRaFHQBybWpWltzKhHLyKRo6AvM7+tkQ27FfQiEi0K+jLzpzTQueewzpAVkUhR0Jd5VVsjA3lnS1dP2KWIiIwaBX2ZwZk3OiArIhGioC8zZ1I9NUljo8bpRSRCKgp6M1tiZpvMrNPMbh9mfcbMlgXrV5nZrGD5H5jZWjNbF/z7htEtf3SlUwnmttSzcZd69CISHScNejNLAncD1wILgJvMbMGQzW4BDrh7B3AXcEewfC/wVnc/D7gZ+NZoFX6mvGpKo3r0IhIplfToLwU63X2Lu/cD9wNLh2yzFLg3uP0AcI2Zmbs/4e4vBMvXA+PMLDMahZ8p89sa2HWwl5eO9IddiojIqKgk6NuB7WX3dwTLht3G3XPAQaB5yDbXA79x9+MuJmNmHzCzNWa2pqsr3G96Wji1CYDf7jgYah0iIqPlrByMNbOFFIdzPjjcenf/irsvdvfFLS0tZ6OkE7p45nhqksavt+wLtQ4RkdFSSdDvBKaX3Z8WLBt2GzNLAU3AvuD+NOD7wHvcffPpFnym1aZTXDBtPCs3K+hFJBoqCfrVwDwzm21maeBGYPmQbZZTPNgKcAPwsLu7mY0Hfgzc7u6PjlbRZ9oVc5tZt/Mg3X25sEsRETltJw36YMz9NuAhYAPwXXdfb2afNrPrgs3uAZrNrBP4GFCagnkb0AF8ysyeDH4mj3orRtnlc5rJF5zVz+0PuxQRkdOWqmQjd18BrBiy7FNlt3uBtw/zuL8F/vY0azzrfm/mBNLJBCu37OP188f855KIyCvSmbHDyNYkuXCGxulFJBoU9CdwxZxm1r9wkINHB8IuRUTktCjoT+CKuc0UHB7XOL2IVDkF/QlcNGM8mVRCwzciUvUU9CeQSSX5vZkTeGzz3rBLERE5LQr6V3BVxyQ27j7M3u7jrtogIlI1FPSv4Mq5xcv1aPhGRKqZgv4VnNfeREMmpeEbEalqCvpXkEomuGxOM492qkcvItVLQX8SV3c0s23/EbbvPxJ2KSIip0RBfxJXdUwC4NFODd+ISHVS0J9Ex+R6JjdkeFQHZEWkSinoT8LMuHJuM4917qVQ8LDLEREZMQV9Ba7qmMS+nn59abiIVCUFfQVee24LNUlj2eptYZciIjJiCvoKTG7I8raL2rl/9XadJSsiVUdBX6EPvnYu/fkC33h0a9iliIiMiIK+QnNb6lmysI1vrtzK4V5do15EqoeCfgQ+9Lq5HOrN8Z1VGqsXkeqhoB+B86eN56qOZr7+6FbymmopIlVCQT9CN14yg92HevXNUyJSNRT0I/T7r2qlNp1k+W9fCLsUEZGKKOhHaFw6yRsXtLJi3S76c4WwyxEROSkF/SlYemE7B48O8MjvusIuRUTkpBT0p+DqeZOYUFuj4RsRqQoK+lNQk0zwpvOm8NNnXqSnLxd2OSIir0hBf4quu2AqRwfy/Jt69SIyxinoT9ElsyZy4fTxfPahTezT9W9EZAxT0J+iRMK44/rzOdw7wKd/9EzY5YiInJCC/jSc29bAra/v4IdPvsDDG18MuxwRkWEp6E/Th1/XwTmt9Xzy+09zSBc7E5ExSEF/mtKpBJ+94QJePNTL//43DeGIyNijoB8FF04fz4df18G/rt3Bfz6jIRwRGVsU9KPkT6+Zx/y2Bm5/cB0HevrDLkdEZJCCfpSkUwnufMeFHDzazwf/Za1OpBKRMaOioDezJWa2ycw6zez2YdZnzGxZsH6Vmc0Kljeb2c/NrNvM/nl0Sx97Fkxt5B/ecSFrnz/AH399Nd0KexEZA04a9GaWBO4GrgUWADeZ2YIhm90CHHD3DuAu4I5geS/wl8Cfj1rFY9x1F0zlczdexNptB7j5a49z8Khm4ohIuCrp0V8KdLr7FnfvB+4Hlg7ZZilwb3D7AeAaMzN373H3X1EM/Nh48/lTuPtdF/HUjpd455dXsudQrJovImNMJUHfDmwvu78jWDbsNu6eAw4CzZUWYWYfMLM1Zramqysal/5dsmgKX3vvJWzbf4Trv/QYW/f2hF2SiMTUmDgY6+5fcffF7r64paUl7HJGzavntXDf+y+nuzfHLfeupncgH3ZJIhJDlQT9TmB62f1pwbJhtzGzFNAE7BuNAqvdBdPH8/mbLmZzVw+f+cnGsMsRkRiqJOhXA/PMbLaZpYEbgeVDtlkO3BzcvgF42N199MqsblfPm8QfXzWLbzy2Vd9KJSJn3UmDPhhzvw14CNgAfNfd15vZp83sumCze4BmM+sEPgYMTsE0s63AncB7zWzHMDN2YuHjS+bTMbmev3jgt+w+qIOzInL2VDRG7+4r3P0cd5/r7v8nWPYpd18e3O5197e7e4e7X+ruW8oeO8vdJ7p7vbtPc/dYXhAmW5PkH995Id29Oa7/4mN07jkcdkkiEhNj4mBsXCxqb2LZB6+gL1fg+i+uZM3W/WGXJCIxoKA/yxa1N/Hgh65kYl2ad311FT9+alfYJYlIxCnoQzCjuZbvfehKzmtv4tbv/IYv/XIzOnYtImeKgj4kE+vSfPt9l/GW86fwmZ9s5H33rmHXwaNhlyUiEaSgD1G2JsnnbryI//XmV/Ho5r288c5HuO/xberdi8ioUtCHLJEw3vfqOTz00ddw3rQmPvHgOt7/zbXs6+4LuzQRiQgF/Rgxs7mOf7nlMv7yLQt45HddLPmn/8fjz2lWjoicPgX9GJJIGLdcPZsf3HoVDZkU//UezcoRkdOnoB+DFkxtHJyVc9t9xVk5A/lC2GWJSJVS0I9RE4JZOUsWtvGZn2zkdX/3C+59bKuugCkiI6agH8OyNUm+8O6LuefmxbQ1Zfmr5et5/d//gu8/sYNCQTNzRKQyCvoxzsy45lWtPPAnV/Cd919Gc32aP1v2W972hUfZ3NUddnkiUgUU9FXCzLhy7iSW33o1d77jArbtP8JbP/8rfvDE0K8GEBF5OQV9lUkkjD+6eBorPvJqFk5t5KPLnuQ9X3ucZau3ae69iAwrFXYBcmqmNI3jvvdfzpd+uZn7V2/n499bR8LW8ep5LfzRxe28cUEb49LJsMsUkTFAQV/FUskEt71hHre+voP1Lxzix+t28cMndvKR+59kckOGv3rrQt50XhtmFnapIhIiBX0EmBmL2ptY1N7EX7zxXFZu2cf/XbGBW7/zG15/bgu3vWEeF88Yr8AXiSkFfcQkEsZVHZP44a1Xce/K57nrp7/j+i8+xtyWOt583hQ6WhuYM6mO2ZPqqMto94vEgd7pEZVKJrjl6tm885LprHhqF8vWbOfzP++k/MKY7ePHsWBqI0sWtvEHC1tpzNaEV7CInDEK+oirz6R4xyXTeccl0+kdyPP8viNs6epmc1c3z+7pZs3WA/z0mRdJP5hg1qRamusytDZmuHjmBC6dPZF5kxtIJjTkI1LNFPQxkq1Jcm5bA+e2NQwuc3ee3P4S//70brbu62Ffdz8rt+zjB0++AEAyYUyqT9PamGXahHFMm1DLvMn1vOacFlobs2E1RURGQEEfc2bGRTMmcNGMCYPL3J0dB46y6rn9bN3bw4uHetl9qJeNuw/zsw176MsVL7B2Tms9M5vrmFSfYWpTlkXtTSxsb2RSXYaE/gqQM8DdKTjkC06+4OQKxd/FhFnxJwFJs8GJB6XtCyf4Mp98wekdyHN0ID/4nAV3+nPOQL7A0EeVnq/0b4lZsYZkwkgEt0vLAfpzBXoHCvTnC7j7y4ZQHSeXL75ua2P2Ze/F0aKgl+OYGdMn1jJ9Yu1x6woFZ+PuwzzybBcrN+9j+/4jPLHtAHu7+1+2XSaVYFw6SV06RW06SbYmSSpppJMJ6jMp6rMpJtalmdKUpbUxS0t9hub6DBPqamgaV0MmNfJzAEpvoKFv6lzBgzcY1CRLb8ZSEDAYGIUC5N0HH29Af77Akf48R/vz5ApOLl8YfIMX3Dnan6e7L8fRgTwD+QIDwYegWfENb0EAFYLnLV2jyIPXLgQ1lwIhUfa4vlyeo/0F+nL5wXA5rs3BPimFWSlwjOKBeQtqMSu280h/jqP9BTyIsFL78+705wr05wrkC8eep1RfaZv8MNdYKr4GgzUkg8Bz4Gh/MUTdvViXgWE4wfMGz+9erCiXd/pyBfpzeTx47oIX98NAsA+j7M3nT+Hud41+0NtY+9q6xYsX+5o1a8IuQ0bocO8Az7xwiGd2HeKlIwP05vL09ufp6c/T05ejL1d8o/blCvT05Tjcm2Nfdx89/cNfjTOdSgRvcscwMjUJsjVJ0slE8QxgK540Vgyv4mscjeiVPZMJC3qpxz4QyiWsuJ5gXaHgL/8goRikyYRRm04xriY5+DxmxR5wIlH8EM6kEoMhXSg4VtZLTSaKt41jRZQC2724vhj4xR4qQG06ybh0EjMr9oLLrradSBz7ICx9WKQSCTI1CdLJYyftJ8xIpxIv+5BOWHHCQbL0gY2TLxRfe+iHUamuoXVDse3j0kmyqeRg+0r/FzXJYx2Cchb8Xxg2+P9Yet3SB2Oh7EMcnEwqSaam+P9rduwDuCQVtKuptob28eNO9KvwisxsrbsvHm6devQyKhqyNVw2p5nL5jSP6HGHewfYfbCXvd397Ovp40BPP4d6cxzqHQCKb3J36B3I05fL059zfrFpDw4sam8iaTAunaQ+k2JcOnUsEIPndxj8SwJKvXd/We84mUiQTAT/GoPDTu7FD5xxNcW/SNIpI5VIDB6cNoqv3ZBNDX4IpZLHPqAKXgyUQoHin/OJY6FWapsljtVa6rWXAjobvK4OhsvpUtBLqBqyNTRka5jXWvlj3vnllQB8/qaLzlBVItGii5qJiEScgl5EJOIU9CIiEaegFxGJOAW9iEjEKehFRCJOQS8iEnEKehGRiBtzl0Awsy7g+dN4iknA3lEqJ2xqy9iktoxNcW/LTHdvGW7FmAv602Vma050vYdqo7aMTWrL2KS2nJiGbkREIk5BLyIScVEM+q+EXcAoUlvGJrVlbFJbTiByY/QiIvJyUezRi4hIGQW9iEjERSbozWyJmW0ys04zuz3sekbCzKab2c/N7BkzW29mHwmWTzSzn5rZs8G/o/9lkmeImSXN7Akz+1Fwf7aZrQr2zzIzS4ddYyXMbLyZPWBmG81sg5ldUeX75c+C37Gnzew+M8tWy74xs6+Z2R4ze7ps2bD7woo+F7TpKTO7OLzKj3eCtvxd8Hv2lJl938zGl637RNCWTWb2X0b6epEIejNLAncD1wILgJvMbEG4VY1IDvjv7r4AuBy4Naj/duBn7j4P+Flwv1p8BNhQdv8O4C537wAOALeEUtXI/RPw7+4+H7iAYpuqcr+YWTvwp8Bid18EJIEbqZ598w1gyZBlJ9oX1wLzgp8PAF88SzVW6hsc35afAovc/Xzgd8AnAIIsuBFYGDzmC0HmVSwSQQ9cCnS6+xZ37wfuB5aGXFPF3H2Xu/8muH2YYpi0U2zDvcFm9wJ/GE6FI2Nm04A3A18N7hvwBuCBYJOqaIuZNQGvAe4BcPd+d3+JKt0vgRQwzsxSQC2wiyrZN+7+CLB/yOIT7YulwDe96NfAeDObcnYqPbnh2uLu/+HuueDur4Fpwe2lwP3u3ufuzwGdFDOvYlEJ+nZge9n9HcGyqmNms4CLgFVAq7vvClbtBkbwzaqh+kfgfwCF4H4z8FLZL3G17J/ZQBfw9WAY6qtmVkeV7hd33wn8PbCNYsAfBNZSnfum5ET7otoz4b8BPwlun3ZbohL0kWBm9cD3gI+6+6HydV6cBzvm58Ka2VuAPe6+NuxaRkEKuBj4ortfBPQwZJimWvYLQDB+vZTiB9hUoI7jhw+qVjXti1diZp+kOJz77dF6zqgE/U5getn9acGyqmFmNRRD/tvu/mCw+MXSn5vBv3vCqm8ErgKuM7OtFIfQ3kBxnHt8MFwA1bN/dgA73H1VcP8BisFfjfsF4PeB59y9y90HgAcp7q9q3DclJ9oXVZkJZvZe4C3Au/3YSU6n3ZaoBP1qYF4weyBN8cDF8pBrqlgwhn0PsMHd7yxbtRy4Obh9M/DDs13bSLn7J9x9mrvPorgfHnb3dwM/B24INquWtuwGtpvZucGia4BnqML9EtgGXG5mtcHvXKk9VbdvypxoXywH3hPMvrkcOFg2xDMmmdkSikOe17n7kbJVy4EbzSxjZrMpHmB+fERP7u6R+AHeRPFI9Wbgk2HXM8Lar6b4J+dTwJPBz5sojm3/DHgW+E9gYti1jrBdrwN+FNyeE/xydgL/CmTCrq/CNlwIrAn2zQ+ACdW8X4C/ATYCTwPfAjLVsm+A+ygeWxig+NfWLSfaF4BRnIm3GVhHcaZR6G04SVs6KY7FlzLgS2XbfzJoyybg2pG+ni6BICIScVEZuhERkRNQ0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIu7/A+QdVGCFHzQGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph.plot(np.arange(len(errors)), errors)\n",
    "graph.axvline(np.argmin(errors))\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth = 2, warm_start= True)\n",
    "\n",
    "min_val_error = float('inf')\n",
    "error_going_up = 0\n",
    "\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(x_train, y_train)\n",
    "    y_pred = gbrt.predict(x_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.27840\n",
      "[1]\tvalidation_0-rmse:0.21113\n",
      "[2]\tvalidation_0-rmse:0.15815\n",
      "[3]\tvalidation_0-rmse:0.12088\n",
      "[4]\tvalidation_0-rmse:0.09705\n",
      "[5]\tvalidation_0-rmse:0.08036\n",
      "[6]\tvalidation_0-rmse:0.07042\n",
      "[7]\tvalidation_0-rmse:0.06499\n",
      "[8]\tvalidation_0-rmse:0.06319\n",
      "[9]\tvalidation_0-rmse:0.06231\n",
      "[10]\tvalidation_0-rmse:0.06212\n",
      "[11]\tvalidation_0-rmse:0.06240\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "xgb_reg.fit(x_train, y_train)\n",
    "y_pred = xgb_reg.predict(x_val)\n",
    "\n",
    "xgb_reg.fit(x_train, y_train, \n",
    "            eval_set=[(x_val, y_val)], early_stopping_rounds=2)\n",
    "y_pred = xgb_reg.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "- Instead of using functions to aggregate predictions, train a model to do the regression for us!\n",
    "- THAT MODEL IS CALLED A BLENDER!\n",
    "- LEARNS TO PREDICT TARGET VALUE GIVEN FIRST LAYER'S PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Load the MNIST data (introduced in Chapter 3), and split it into a training set, a\n",
    "validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation,\n",
    "and 10,000 for testing). Then train various classifiers, such as a Random\n",
    "Forest classifier, an Extra-Trees classifier, and an SVM. Next, try to combine\n",
    "them into an ensemble that outperforms them all on the validation set, using a\n",
    "soft or hard voting classifier. Once you have found one, try it on the test set. How\n",
    "much better does it perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Run the individual classifiers from the previous exercise to make predictions on\n",
    "the validation set, and create a new training set with the resulting predictions:\n",
    "each training instance is a vector containing the set of predictions from all your\n",
    "classifiers for an image, and the target is the images class. Train a classifier on\n",
    "this new training set. Congratulations, you have just trained a blender, and\n",
    "together with the classifiers they form a stacking ensemble! Now lets evaluate the\n",
    "ensemble on the test set. For each image in the test set, make predictions with all\n",
    "your classifiers, then feed the predictions to the blender to get the ensembles predictions.\n",
    "How does it compare to the voting classifier you trained earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
